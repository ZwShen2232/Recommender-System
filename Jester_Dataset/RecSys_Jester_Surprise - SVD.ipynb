{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Standard Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Surprise library\n",
    "from surprise import Reader, Dataset, accuracy, SVD, NMF, KNNBasic, KNNWithMeans\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Datasets\n",
    "jester_df = pd.read_csv(r\"jester_ratings.csv\")\n",
    "jester_text_df = pd.read_csv(r\"jester_items.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code with Surprise and SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearch\n",
    "#parameters = {\"n_factors\": [100, 150, 200],\n",
    "#              \"reg_all\": [0.04, 0.06],\n",
    "#              \"n_epochs\": [5, 10, 15],\n",
    "#              \"lr_all\": [.002, .005, .01]}\n",
    "#gridsvd = GridSearchCV(SVD, param_grid=parameters, n_jobs=-1)\n",
    "#gridsvd.fit(data)\n",
    "#print(gridsvd.best_score)\n",
    "#print(gridsvd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data\n",
    "reader = Reader(rating_scale=(-10, 10))\n",
    "data = Dataset.load_from_df(jester_df[['userId', 'jokeId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors=100, reg_all=0.06, n_epochs=5, lr_all=.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Fitting KNNBasic model to training set\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Test the model on the testing set\n",
    "predictions = svd.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 38307      item: 16         r_ui = 9.47   est = -1.72   {'was_impossible': False}\n",
      "user: 35938      item: 39         r_ui = 5.00   est = -8.89   {'was_impossible': False}\n",
      "user: 47316      item: 148        r_ui = -0.06   est = 10.00   {'was_impossible': False}\n",
      "user: 23656      item: 69         r_ui = 8.28   est = -0.01   {'was_impossible': False}\n",
      "user: 21600      item: 62         r_ui = 3.69   est = 2.25   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# Printing users actual ratings and the predicted ratings\n",
    "for prediction in predictions[0:5]:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.2614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.261393768260221"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the performance metrics\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspiration from https://www.kaggle.com/code/laowingkin/netflix-movie-recommendation\n",
    "# Function to recommend an user a number of recommendations\n",
    "def recommend_SVD(userId, num_recommendations):\n",
    "    user_df = jester_text_df.copy()\n",
    "    user_df = user_df.reset_index()\n",
    "\n",
    "    data = Dataset.load_from_df(jester_df[['userId', 'jokeId', 'rating']], reader)\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "    svd.fit(trainset)\n",
    "\n",
    "    user_df['Estimate_Score'] = user_df['jokeId'].apply(lambda x: svd.predict(userId, x).est)\n",
    "\n",
    "    user_df = user_df.drop('jokeId', axis = 1)\n",
    "\n",
    "    user_df = user_df.sort_values('Estimate_Score', ascending=False)\n",
    "    print(user_df.head(num_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                           jokeText  Estimate_Score\n",
      "16      16  How many men does it take to screw in a light ...        5.319786\n",
      "12      12  They asked the Japanese visitor if they have e...        4.991301\n",
      "61      61  A group of  managers were given the assignment...        4.405402\n",
      "28      28  An old Scotsmen is sitting with a younger Scot...        4.272971\n",
      "6        6  How many feminists does it take to screw in a ...        4.228431\n",
      "67      67  A man piloting a hot air balloon discovers he ...        4.163693\n",
      "131    131  Mickey Mouse is having a nasty divorce with Mi...        4.153905\n",
      "126    126  A little boy goes to his dad and asks, \"What i...        3.871449\n",
      "35      35  A guy walks into a bar, orders a beer and says...        3.844877\n",
      "18      18  Q: If a person who speaks three languages is c...        3.696313\n"
     ]
    }
   ],
   "source": [
    "# Recommend user 100 with the top 10 jokes\n",
    "recommend_SVD(100, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    4.2711  4.2650  4.2679  4.2771  4.2881  4.2738  0.0082  \n",
      "MAE (testset)     3.1345  3.1355  3.1394  3.1447  3.1493  3.1407  0.0056  \n",
      "Fit time          3.37    3.57    3.59    3.60    3.61    3.55    0.09    \n",
      "Test time         2.51    2.08    2.56    2.13    2.15    2.29    0.21    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([4.27110858, 4.26502461, 4.26786347, 4.27710867, 4.28813058]),\n",
       " 'test_mae': array([3.13454857, 3.13554211, 3.13941935, 3.14473311, 3.14934597]),\n",
       " 'fit_time': (3.365025520324707,\n",
       "  3.572671890258789,\n",
       "  3.591733694076538,\n",
       "  3.602407693862915,\n",
       "  3.607764959335327),\n",
       " 'test_time': (2.5077929496765137,\n",
       "  2.0768637657165527,\n",
       "  2.5604665279388428,\n",
       "  2.12835431098938,\n",
       "  2.153841257095337)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(svd, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
